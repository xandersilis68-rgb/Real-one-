<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Body Part Detector</title>
  <!-- TensorFlow.js -->
  <script id="tfjs-script" src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.21.0/dist/tf.min.js" crossorigin="anonymous"></script>
  <!-- PoseNet -->
  <script id="posenet-script" src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet@2.2.2" crossorigin="anonymous"></script>
  <!-- Face Landmarks Detection -->
  <script id="face-landmarks-script" src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection@1.0.2" crossorigin="anonymous"></script>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 20px;
      background-color: #f4f4f9;
      color: #333;
    }
    h1 {
      color: #007f8b;
      text-align: center;
    }
    p {
      text-align: center;
      max-width: 800px;
      margin: 0 auto 20px;
    }
    .container {
      max-width: 800px;
      margin: 0 auto;
      padding: 20px;
      background: white;
      border-radius: 8px;
      box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
    }
    #upload {
      display: block;
      margin: 20px auto;
      padding: 10px 20px;
      background-color: #007f8b;
      color: white;
      border: none;
      border-radius: 4px;
      cursor: pointer;
      font-size: 16px;
    }
    #upload:hover {
      background-color: #005f6b;
    }
    #upload:disabled {
      background-color: #ccc;
      cursor: not-allowed;
    }
    #reset {
      display: block;
      margin: 10px auto;
      padding: 10px 20px;
      background-color: #dc3545;
      color: white;
      border: none;
      border-radius: 4px;
      cursor: pointer;
      font-size: 16px;
    }
    #reset:hover {
      background-color: #c82333;
    }
    #retry {
      display: none;
      margin: 10px auto;
      padding: 10px 20px;
      background-color: #007bff;
      color: white;
      border: none;
      border-radius: 4px;
      cursor: pointer;
      font-size: 16px;
    }
    #retry:hover {
      background-color: #0056b3;
    }
    #canvas {
      display: block;
      margin: 20px auto;
      max-width: 100%;
      border: 1px solid #ccc;
      border-radius: 4px;
      box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
    }
    #loading {
      text-align: center;
      font-style: italic;
      color: #666;
      display: none;
    }
    #model-loading {
      text-align: center;
      font-style: italic;
      color: #666;
    }
    #error {
      text-align: center;
      color: #dc3545;
      display: none;
    }
    @media (max-width: 600px) {
      .container {
        padding: 10px;
      }
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>Body Part Detector</h1>
    <p>Select an image file containing one or more people. The app will detect and overlay body parts and facial landmarks for up to 4 individuals.</p>
    <input type="file" id="upload" accept="image/*" disabled>
    <button id="reset">Reset</button>
    <button id="retry">Retry Loading Models</button>
    <p id="model-loading">Loading models... This may take a moment.</p>
    <p id="loading">Processing image...</p>
    <p id="error"></p>
    <canvas id="canvas"></canvas>
  </div>

  <script>
    // Check WebGL support
    function checkWebGLSupport() {
      const canvas = document.createElement('canvas');
      const gl = canvas.getContext('webgl') || canvas.getContext('experimental-webgl');
      if (!gl) {
        document.getElementById("error").textContent = "WebGL is not supported or disabled. Please enable WebGL or use Chrome/Edge.";
        document.getElementById("error").style.display = "block";
        document.getElementById("model-loading").style.display = "none";
        document.getElementById("retry").style.display = "block";
        return false;
      }
      return true;
    }

    // Check if libraries are loaded
    function checkLibrariesLoaded() {
      return new Promise((resolve, reject) => {
        const timeout = setTimeout(() => {
          reject(new Error("TensorFlow.js, PoseNet, or Face Landmarks Detection failed to load within 30 seconds."));
        }, 30000);

        function check() {
          if (window.tf && window.posenet && window.faceLandmarksDetection) {
            clearTimeout(timeout);
            resolve();
          } else {
            setTimeout(check, 100);
          }
        }
        check();
      });
    }

    // Custom drawing functions
    function drawLandmarks(ctx, keypoints, options) {
      ctx.fillStyle = options.color || "#FF0000";
      ctx.strokeStyle = options.color || "#FF0000";
      ctx.lineWidth = options.lineWidth || 2;
      for (const keypoint of keypoints) {
        const confidence = keypoint.score !== undefined ? keypoint.score : 0.5;
        if (confidence < 0.5) continue;
        const x = keypoint.position ? keypoint.position.x : keypoint.x;
        const y = keypoint.position ? keypoint.position.y : keypoint.y;
        if (x == null || y == null) continue; // Skip invalid keypoints
        ctx.beginPath();
        ctx.arc(x, y, 3, 0, 2 * Math.PI);
        ctx.fill();
      }
    }

    function drawConnectors(ctx, keypoints, connections, options) {
      ctx.strokeStyle = options.color || "#00FF00";
      ctx.lineWidth = options.lineWidth || 4;
      ctx.beginPath();
      for (const [startIdx, endIdx] of connections) {
        const start = keypoints[startIdx];
        const end = keypoints[endIdx];
        const startConfidence = start.score !== undefined ? start.score : 0.5;
        const endConfidence = end.score !== undefined ? end.score : 0.5;
        if (startConfidence < 0.5 || endConfidence < 0.5) continue;
        const startX = start.position ? start.position.x : start.x;
        const startY = start.position ? start.position.y : start.y;
        const endX = end.position ? end.position.x : end.x;
        const endY = end.position ? end.position.y : end.y;
        if (startX == null || startY == null || endX == null || endY == null) continue;
        ctx.moveTo(startX, startY);
        ctx.lineTo(endX, endY);
      }
      ctx.stroke();
    }

    // Initialize models
    async function initializeModels() {
      if (!checkWebGLSupport()) return;

      const error = document.getElementById("error");
      const modelLoading = document.getElementById("model-loading");
      const retry = document.getElementById("retry");

      try {
        // Wait for libraries to load
        await checkLibrariesLoaded();
        console.log("Libraries loaded: TensorFlow.js, PoseNet, Face Landmarks Detection");

        // Set backend with fallback to CPU
        try {
          await tf.setBackend('webgl');
          await tf.ready();
          console.log("TensorFlow.js backend:", tf.getBackend());
        } catch (err) {
          console.warn("WebGL backend failed, falling back to CPU:", err);
          await tf.setBackend('cpu');
          await tf.ready();
          console.log("TensorFlow.js backend:", tf.getBackend());
        }

        let posenetModel, faceLandmarksModel;

        // Load PoseNet
        try {
          posenetModel = await posenet.load({
            architecture: "MobileNetV1",
            outputStride: 16,
            inputResolution: { width: 640, height: 480 },
            multiplier: 0.75,
            maxPoses: 4
          });
          console.log("PoseNet model loaded successfully");
        } catch (err) {
          throw new Error(`Failed to load PoseNet: ${err.message}`);
        }

        // Load Face Landmarks Detection
        try {
          faceLandmarksModel = await faceLandmarksDetection.load(
            faceLandmarksDetection.SupportedPackages.mediapipeFacemesh,
            { maxFaces: 4, refineLandmarks: false }
          );
          console.log("Face Landmarks Detection model loaded successfully");
        } catch (err) {
          throw new Error(`Failed to load Face Landmarks Detection: ${err.message}`);
        }

        // Enable upload button
        document.getElementById("upload").disabled = false;
        modelLoading.style.display = "none";

        // Handle file upload
        const upload = document.getElementById("upload");
        const reset = document.getElementById("reset");
        const canvas = document.getElementById("canvas");
        const ctx = canvas.getContext("2d");
        const loading = document.getElementById("loading");

        upload.addEventListener("change", async (e) => {
          const file = e.target.files[0];
          if (!file) return;

          loading.style.display = "block";
          error.style.display = "none";

          let img;
          try {
            img = new Image();
            img.src = URL.createObjectURL(file);

            await new Promise((resolve, reject) => {
              img.onload = resolve;
              img.onerror = () => reject(new Error("Image failed to load"));
            });

            canvas.width = img.width;
            canvas.height = img.height;
            ctx.drawImage(img, 0, 0);

            // Run PoseNet detection
            let poses;
            try {
              poses = await posenetModel.estimatePoses(img, {
                flipHorizontal: false,
                maxDetections: 4,
                scoreThreshold: 0.5
              });
            } catch (err) {
              throw new Error(`PoseNet inference failed: ${err.message}`);
            }

            const POSE_CONNECTIONS = [
              [5, 6], [5, 7], [7, 9], [6, 8], [8, 10], // Arms
              [5, 11], [6, 12], [11, 12], // Shoulders to hips
              [11, 13], [13, 15], [12, 14], [14, 16] // Legs
            ];

            for (const pose of poses) {
              drawLandmarks(ctx, pose.keypoints, { color: "#FF0000", lineWidth: 2 });
              drawConnectors(ctx, pose.keypoints, POSE_CONNECTIONS, { color: "#00FF00", lineWidth: 4 });
            }

            // Run Face Landmarks Detection
            let faces;
            try {
              faces = await faceLandmarksModel.estimateFaces({
                input: img,
                returnTensors: false,
                flipHorizontal: false,
                predictIrises: false
              });
            } catch (err) {
              throw new Error(`Face Landmarks Detection inference failed: ${err.message}`);
            }

            const FACE_CONNECTIONS = [
              [10, 338], [338, 297], [297, 332], [332, 284], [284, 251], // Right eye
              [263, 466], [466, 388], [388, 387], [387, 386], [386, 385], // Left eye
              [1, 27], [27, 23], [23, 144], [144, 145], [145, 153], // Nose and mouth
              [0, 17], [17, 314], [314, 405], [405, 321], [321, 375] // Face outline
            ];

            for (const face of faces) {
              drawLandmarks(ctx, face.keypoints, { color: "#0000FF", lineWidth: 2 });
              drawConnectors(ctx, face.keypoints, FACE_CONNECTIONS, { color: "#FFFF00", lineWidth: 2 });
            }

            // Clean up tensors
            tf.disposeVariables();
          } catch (err) {
            error.textContent = `Error processing image: ${err.message}. Try a different image, check your network, or use Chrome/Edge.`;
            error.style.display = "block";
            console.error("Image processing error:", err);
          } finally {
            loading.style.display = "none";
            if (img) URL.revokeObjectURL(img.src);
          }
        });

        reset.addEventListener("click", () => {
          ctx.clearRect(0, 0, canvas.width, canvas.height);
          upload.value = "";
          error.style.display = "none";
          loading.style.display = "none";
          tf.disposeVariables(); // Clean up any remaining tensors
        });
      } catch (err) {
        error.textContent = `Initialization error: ${err.message}. Please click Retry, disable ad-blockers, check your network, or use Chrome/Edge.`;
        error.style.display = "block";
        modelLoading.style.display = "none";
        retry.style.display = "block";
        console.error("Initialization error:", err);
      }
    }

    // Retry button handler
    document.getElementById("retry").addEventListener("click", () => {
      document.getElementById("error").style.display = "none";
      document.getElementById("model-loading").style.display = "block";
      document.getElementById("retry").style.display = "none";
      initializeModels();
    });

    // Start initialization
    initializeModels();
  </script>
</body>
</html>
